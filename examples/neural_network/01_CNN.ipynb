{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBXNbvMLPoY3"
   },
   "source": [
    "---\n",
    "\n",
    "# ***01 - CNN***\n",
    "\n",
    "---\n",
    "\n",
    "**Aprendizagem de Máquina**\n",
    "\n",
    "Gustavo H. G. Matsushita (gustavomatsushita@ufpr.br)\n",
    "\n",
    "Prof. Luiz Eduardo S. Oliveira (luiz.oliveira@ufpr.br)\n",
    "\n",
    "---\n",
    "\n",
    "**Universidade Federal do Paraná**\n",
    "\n",
    "Departamento de Informática\n",
    "\n",
    "http://web.inf.ufpr.br/luizoliveira\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPiB7p78mHVZ"
   },
   "source": [
    "\n",
    "**Keras:**\n",
    "https://keras.io/getting_started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGQYdX7ww5Z"
   },
   "source": [
    "#Importando do Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYrRT74AwoIz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a145c0899d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikhMIDRFx5ow"
   },
   "source": [
    "#Importando módulos no Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5uZAfmgSQ1j"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35ade07c1509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_A1VYGHzRgks"
   },
   "source": [
    "#Verificando GPU\n",
    "\n",
    "(Editar > Configurações de Notebook > Acelerador de hardware > **GPU** > Salvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdgULoWDNRwh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mksTnlljPcCt"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lppn1n_3Etbj"
   },
   "source": [
    "#Definindo algumas variáveis\n",
    "(número de classes, épocas, tamanho dos batch, **arquivos de entrada**...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DN9-TpiKgEld"
   },
   "outputs": [],
   "source": [
    "## Google Drive\n",
    "drive_path = '/content/drive/My Drive/Colab Notebooks/Aulas/'\n",
    "\n",
    "## Classes\n",
    "num_classes = 12\n",
    "\n",
    "## Batch Size\n",
    "batch_size = 64\n",
    "\n",
    "## Epochs\n",
    "n_epochs = 64\n",
    "\n",
    "## Train and Test files\n",
    "train_file = drive_path + 'train.txt'\n",
    "test_file = drive_path + 'test.txt'\n",
    "\n",
    "## Input Image Dimension\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXOChfRKF76Z"
   },
   "source": [
    "#Funções para ler e preparar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbwc8aB5gmYs"
   },
   "outputs": [],
   "source": [
    "## Resize\n",
    "\n",
    "def resize_data(data, size, convert):\n",
    "\n",
    "\tif convert:\n",
    "\t\tdata_upscaled = np.zeros((data.shape[0], size[0], size[1], 3))\n",
    "\telse:\n",
    "\t\tdata_upscaled = np.zeros((data.shape[0], size[0], size[1]))\n",
    "\tfor i, img in enumerate(data):\n",
    "\t\tlarge_img = cv2.resize(img, dsize=(size[1], size[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\t\tdata_upscaled[i] = large_img\n",
    "\n",
    "\t#print (np.shape(data_upscaled))\n",
    "\treturn data_upscaled\n",
    "  \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwetklxVgK4e"
   },
   "outputs": [],
   "source": [
    "## Load Images\n",
    "\n",
    "def load_images(image_paths, convert=False):\n",
    "\n",
    "\tx = []\n",
    "\ty = []\n",
    "\tfor image_path in image_paths:\n",
    "\n",
    "\t\tpath, label = image_path.split(' ')\n",
    "\t\t\n",
    "\t\t## Image path\n",
    "\t\tpath= drive_path + 'data/' + path\n",
    "\t\tprint (path)\n",
    "\n",
    "\t\tif convert:\n",
    "\t\t\timage_pil = Image.open(path).convert('RGB') \n",
    "\t\telse:\n",
    "\t\t\timage_pil = Image.open(path).convert('L')\n",
    "\n",
    "\t\timg = np.array(image_pil, dtype=np.uint8)\n",
    "\n",
    "\t\tx.append(img)\n",
    "\t\ty.append([int(label)])\n",
    "\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\n",
    "\tif np.min(y) != 0: \n",
    "\t\ty = y-1\n",
    "\n",
    "\treturn x, y\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nvT443Phisg"
   },
   "outputs": [],
   "source": [
    "## Load Dataset\n",
    "\n",
    "def load_dataset(train_file, test_file, resize, convert=False, size=(224,224)):\n",
    "\n",
    "\tarq = open(train_file, 'r')\n",
    "\ttexto = arq.read()\n",
    "\ttrain_paths = texto.split('\\n')\n",
    "\t\n",
    "\tprint ('Size:', size)\n",
    "\n",
    "\ttrain_paths.remove('') # Remove empty lines\n",
    "\ttrain_paths.sort()\n",
    "\n",
    "\tprint (\"Loading training set...\")\n",
    "\tx_train, y_train = load_images(train_paths, convert)\n",
    " \n",
    "\tarq = open(test_file, 'r')\n",
    "\ttexto = arq.read()\n",
    "\ttest_paths = texto.split('\\n')\n",
    "\n",
    "\ttest_paths.remove('') # Remove empty lines\n",
    "\ttest_paths.sort()\n",
    " \n",
    "\tprint (\"Loading testing set...\")\n",
    "\tx_test, y_test = load_images(test_paths, convert)\n",
    "\n",
    "\tif resize:\n",
    "\t\tprint (\"Resizing images...\")\n",
    "\t\tx_train = resize_data(x_train, size, convert)\n",
    "\t\tx_test = resize_data(x_test, size, convert)\n",
    "\n",
    "\tif not convert:\n",
    "\t\tx_train = x_train.reshape(x_train.shape[0], size[0], size[1], 1)\n",
    "\t\tx_test = x_test.reshape(x_test.shape[0], size[0], size[1], 1)\n",
    "\n",
    "\tprint (np.shape(x_train))\n",
    "\treturn (x_train, y_train), (x_test, y_test)\n",
    " \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLMlXWRlGxwY"
   },
   "source": [
    "# **1. Carregando as bases de treino e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVSYip88hlOv"
   },
   "outputs": [],
   "source": [
    "print (\"Loading database...\")\n",
    "\n",
    "## Gray Scale\n",
    "#input_shape = (img_rows, img_cols, 1)\n",
    "#(x_train, y_train), (x_test, y_test) = load_dataset(train_file, test_file, resize=True, convert=False, size=(img_rows, img_cols))\n",
    "\n",
    "## RGB\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset(train_file, test_file, resize=True, convert=True, size=(img_rows, img_cols))\n",
    "\n",
    "## Save for the confusion matrix\n",
    "label = []\n",
    "for i in range(len(x_test)):\n",
    "\tlabel.append(y_test[i][0])\n",
    "\n",
    "## Normalize images\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "#print ('\\n','x_train shape:', x_train.shape)\n",
    "\n",
    "print ('\\n',x_train.shape[0], 'train samples')\n",
    "print ('\\n',x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "## Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QXidk7CIcXG"
   },
   "source": [
    "# **2. Difinindo o modelo da CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nccYGPYInFUd"
   },
   "outputs": [],
   "source": [
    "## Create CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## Print CNN layers\n",
    "print ('Network structure ----------------------------------')\n",
    "\n",
    "# for i, layer in enumerate(model.layers):\n",
    "# \tprint(i,layer.name)\n",
    "# \tif hasattr(layer, 'output_shape'):\n",
    "# \t\tprint(layer.output_shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print ('----------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0ZBMm0CJkbT"
   },
   "source": [
    "# **3. Configurando e treinando a CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8GAzseUtYMw"
   },
   "outputs": [],
   "source": [
    "## Configures the model for training\n",
    "model.compile(metrics=['accuracy'], loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(learning_rate=0.01))\n",
    "\n",
    "## Trains the model\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print ('\\n----------------------------------------------------\\n')\n",
    "print ('Test loss:', score[0])\n",
    "print ('Test accuracy:', score[1])\n",
    "print ('\\n----------------------------------------------------\\n')\n",
    "\n",
    "## Classes predicted\n",
    "#print (model.predict_classes(x_test)) \n",
    "\n",
    "## Classes probability\n",
    "#print (model.predict_proba(x_test)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YX_SmrdxKwQH"
   },
   "source": [
    "#Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kS-JQ6OL6K0m"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "y_pred = model.predict_classes(x_test)\n",
    "# y_pred = y_prob.argmax(axis=-1)\n",
    "for i in range(len(x_test)):\n",
    "\tpred.append(y_pred[i])\n",
    "print (confusion_matrix(label, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftryNw3tLhhK"
   },
   "source": [
    "#Plotando gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMIEsNUM6TPY"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy'] # history['acc'] / history['accuracy']\n",
    "val_acc = history.history['val_accuracy'] # history['val_acc'] / history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/2IS89cU2mgHQJtKhOR3g",
   "collapsed_sections": [],
   "name": "01_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
