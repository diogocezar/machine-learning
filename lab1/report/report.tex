\documentclass[12pt]{article}
\usepackage{class/sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{color}
\usepackage{listings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% C O N F I G U R A Ç Õ E S  D O S   C Ó D I G O S %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\lstset{
	numbers=left,
	stepnumber=1,
	firstnumber=1,
	numberstyle=\tiny,
	extendedchars=true,
	breaklines=true,
	frame=single,
	showstringspaces=false,
	xleftmargin=2.5em,
	framexleftmargin=2em,
	basicstyle=\small,
}

\renewcommand{\lstlistingname}{Código}
\renewcommand{\lstlistlistingname}{Lista de Códigos}

\sloppy

\title{Aprendizagem de Máquina (2020/Período Especial) - Impactos da Representação}

\author{Diogo C. T. Batista\inst{1}}

\address{Universidade Federal do Paraná (UFPR)\\
	Curitiba -- Paraná -- Brasil
	\email{diogo@diogocezar.com}
	}

\begin{document}

\maketitle

\section{Representação}

Esta atividade laboratorial tem como objetivo a investigação exploratória de um algorítmo para a classificação de imagens. As imagens analisadas são representações manuscritas de dígitos de 10 categorias diferentes, que representam os número decimais $0,1,2,3,4,5,6,7,8,9$. A Figura \ref{fig:image_1_digits} demonstra alguns exemplos das imagens que devem ser classificadas.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=15em]{images/image_1_digits.jpg}
  \caption{Dígitos a serem classificados}
  \label{fig:image_1_digits}
\end{figure}

Além das figuras, um arquivo de texto rotula cada uma das imagens, classificando-a em alguma categoria. Como no exemplo do Código \ref{code:exemplo_rotulos}.

\begin{lstlisting}[caption={Exemplo dos Rótulos},captionpos=b,frame=single,label={code:exemplo_rotulos}]
data/cdf0361_07_13_0.jpg 0
data/cdf1697_45_29_0.jpg 0
data/cdf0872_30_6_1.jpg 0
data/cdf0371_24_4_0.jpg 0
data/cdf1539_20_17_2.jpg 0
\end{lstlisting}

A atividade se iniciou com base na implementação do programa \textit{digits.py} que extrai uma representação bem simples de cada uma das imagens. Para cada imagem, se gera uma nova imagem no tamanho de $10 x 20$. E para cada pixel, verifica-se o seu valor de intensidade; se esse valor for maior que $128$, a característica é igual a $1$, caso contrário $0$.

Neste ponto, notou-se a possibilidade da primeira exploração. Além do tamanho inicial proposto, uma adaptação no algorítmo realizou uma análise em toda a base de imagens, obtendo outras dimensões para verificação. As estratégias adotadas foram:

\begin{enumerate}
  \item Obter a média entre todas alturas e larguras;
  \item Obter a mediana entre todas alturas e larguras;
  \item Obter os valores máximos entre alturas e larguras;
\end{enumerate}

Após análise dos resultados, notou-se que a média e a mediana retornaram resultados muitos similares, por isso, optou-se apenas pela utilização da mediana. A Tabela \ref{tab:estrategias_representacao} mostra as coleções utilizadas nos experimentos. Além da médiana (med\_x, med\_y), os maiores valores encontrados para as dimensões (max\_x e max\_y) também foram considerados. E ainda, empiramente os valores de $x,y$ como $[20,40]$ e $[30,60]$.

\begin{table}[!htb]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
  \hline
  \textbf{X\_Source} & \textbf{Y\_Source} & \textbf{X} & \textbf{Y} & \textbf{File Size} & \textbf{Execution Time (s)} \\ \hline
  20                 & 10                 & 20         & 10         & 2180534            & 1.57                    \\ \hline
  40                 & 20                 & 40         & 20         & 9377970            & 4.84                    \\ \hline
  60                 & 30                 & 60         & 30         & 22978779           & 11.04                   \\ \hline
  med\_x             & med\_y             & 36         & 46         & 20962221           & 10.54                   \\ \hline
  max\_x             & max\_y             & 99         & 81         & 110050116          & 46.63                   \\ \hline
  \end{tabular}
  \caption{Estratégias de representação}
  \label{tab:estrategias_representacao}
\end{table}

Para automatização da geração das representações, foram criadas adaptações no código para que fosse possível utilizar como entrada um arquivo do tipo JSON demonstrado no Código \ref{code:json_representacao}:

\begin{lstlisting}[caption={JSON para representações},captionpos=b,frame=single,label={code:json_representacao}]
[
  {
    "data": "features_20_10",
    "x": 20,
    "y": 10
  },
  ...
]
\end{lstlisting}

Neste JSON, \textit{data} é o nome da coleção de representações, $x$ e $y$ podem ser valores fixos ou terem os valores para obtenção dinâmica de: \textit{avg\_x, avg\_y, med\_x, med\_y, max\_x, max\_y}.

\section{Experimentos}

Assim como na adaptação do primeiro algoritmo, um sistema de entrada JSON possibilitou a variação de combinações para análise de diferentes resultados.

\begin{itemize}
  \item O arquivo de representação fonte; as variações testadas foram: [features\_10\_20, features\_20\_40, features\_30\_60, features\_46\_36, features\_81\_99]
  \item Ativar ou desativar a normalização; as variações testadas foram: [0,1]
  \item Alterar o tipo de distância; as variações testadas foram: [eucledian, manhattan]
  \item Alterar o K; as variações testadas foram: [1,3,4,5,6,7,8,9,10,11,12,13]. Foram considerados os $K$ pares, apenas para efeito de comparações, sabendo-se se sua ineficiência por natureza.
\end{itemize}

\newpage

O Código \ref{code:json_experimentos} mostra as opções de entrada para o algorítmo, podendo variar:

\begin{lstlisting}[caption={JSON para experimentos},captionpos=b,frame=single,label={code:json_experimentos}]
[
  {
    "data": "features_20_10",
    "normalized": 0,
    "distance": "euclidean",
    "k": 1
  },
  ...
]
\end{lstlisting}

\section{Resultados}

Foram realizadas \textit{240} execuções para as variações listadas anteriormente. Os \textit{20} melhores resultados (ordenados por Acurácia e F1Score) estão detalhados na Tabela \ref{tab:resultados_melhores}. Já os 20 piores resultados,  (ordenados por Acurácia e F1Score) estão detalhados na Tabela \ref{tab:resultados_piores}

Pode-se observar que os melhores resultados foram obtidos a partir das representações que consideraram as \textit{maiores} alturas e larguras das imagens (81x99). Isso acontece pois, no momento em que se realiza a compressão das imagens, características são perdidas. O melhor resultado teve a \textit{Acurácia} de $0,927$ e o \textit{F1Score} de $0,928$ demorando $962$ segundos para execução completa.

Já para nos piores resultados, nota-se que foram obtidos na variação de K: $K=13$, $K=12$, $K=11$. Quanto ao $K$ para os melhores resultados, percebe-se que foram obtidos com $K=1$, seguido de $K=3$ e $K=5$. Isso mostra que a distribuição possui uma particularidade interessante, na qual ao se comparar apenas os vizinhos mais próximos se consegue um melhor resultado. Como já esperado, para os resultados nos quais $K$ tinha um valor par, seus resultados foram menos eficientes.

Em outra análise, a estratégia de obter as médias das alturas e larguras também apresentaram resultados significativos (imagens de dimensão $46x36$), mas ficaram empatadas com a estratégia empírica que utiliza imagens $20x40$. O destaque é para o tempo de execução. Com a \textit{features\_20\_40} conseguiu-se uma Acurácia de $0,925$ e o F1Score de $0,926$ demorando apenas $43$ segundos para execução completa.

As normalizações não parecem fazer muita diferença nos resultados, pois estes já se encontram bem distribuídos.

Em geral a alteração da estratégia de medição das distâncias (\textit{euclidean} e \textit{manhattan}) não influenciaram em uma melhoria da \textit{Acurácia} ou do \textit{F1Score}. O que se pode notar, foi que nos testes executados a estratégia \textit{manhattan} impacta negativamente no tempo de execução.

\begin{table}[!htb]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  \textbf{Experiment} & \textbf{Normalized} & \textbf{Distance} & \textbf{K} & \textbf{Accuracy} & \textbf{F1Score} & \textbf{Execution Time (s)} \\ \hline
  features\_81\_99    & 0                   & euclidean         & 1          & 0,927             & 0,928            & 962                     \\ \hline
  features\_81\_99    & 0                   & manhattan         & 1          & 0,927             & 0,928            & 1.386                   \\ \hline
  features\_81\_99    & 1                   & euclidean         & 1          & 0,927             & 0,928            & 1.772                   \\ \hline
  features\_81\_99    & 1                   & manhattan         & 1          & 0,927             & 0,928            & 2.495                   \\ \hline
  features\_20\_40    & 0                   & euclidean         & 1          & 0,925             & 0,926            & 43                      \\ \hline
  features\_20\_40    & 0                   & manhattan         & 1          & 0,925             & 0,926            & 86                      \\ \hline
  features\_20\_40    & 1                   & euclidean         & 1          & 0,925             & 0,926            & 127                     \\ \hline
  features\_20\_40    & 1                   & manhattan         & 1          & 0,925             & 0,926            & 170                     \\ \hline
  features\_46\_36    & 0                   & euclidean         & 1          & 0,925             & 0,926            & 597                     \\ \hline
  features\_46\_36    & 0                   & manhattan         & 1          & 0,925             & 0,926            & 686                     \\ \hline
  features\_46\_36    & 1                   & euclidean         & 1          & 0,925             & 0,926            & 771                     \\ \hline
  features\_46\_36    & 1                   & manhattan         & 1          & 0,925             & 0,926            & 859                     \\ \hline
  features\_30\_60    & 0                   & euclidean         & 1          & 0,924             & 0,924            & 214                     \\ \hline
  features\_30\_60    & 0                   & manhattan         & 1          & 0,924             & 0,924            & 314                     \\ \hline
  features\_30\_60    & 1                   & euclidean         & 1          & 0,924             & 0,924            & 406                     \\ \hline
  features\_30\_60    & 1                   & manhattan         & 1          & 0,924             & 0,924            & 504                     \\ \hline
  features\_20\_40    & 0                   & euclidean         & 3          & 0,920             & 0,921            & 46                      \\ \hline
  features\_20\_40    & 0                   & manhattan         & 3          & 0,920             & 0,921            & 89                      \\ \hline
  features\_20\_40    & 1                   & euclidean         & 3          & 0,920             & 0,921            & 131                     \\ \hline
  features\_20\_40    & 1                   & manhattan         & 3          & 0,920             & 0,921            & 173                     \\ \hline
  \end{tabular}
  \caption{Melhores Resultados}
  \label{tab:resultados_melhores}
\end{table}

\begin{table}[!htb]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  \textbf{Experiment} & \textbf{Normalized} & \textbf{Distance} & \textbf{K} & \textbf{Accuracy} & \textbf{F1Score} & \textbf{Execution Time} \\ \hline
  features\_20\_40    & 0                   & euclidean         & 13         & 0,872             & 0,875            & 82                      \\ \hline
  features\_20\_40    & 0                   & manhattan         & 13         & 0,872             & 0,875            & 124                     \\ \hline
  features\_20\_40    & 1                   & euclidean         & 13         & 0,872             & 0,875            & 166                     \\ \hline
  features\_20\_40    & 1                   & manhattan         & 13         & 0,872             & 0,875            & 208                     \\ \hline
  features\_20\_40    & 0                   & euclidean         & 11         & 0,874             & 0,876            & 75                      \\ \hline
  features\_20\_40    & 0                   & manhattan         & 11         & 0,874             & 0,876            & 117                     \\ \hline
  features\_20\_40    & 1                   & euclidean         & 11         & 0,874             & 0,876            & 159                     \\ \hline
  features\_20\_40    & 1                   & manhattan         & 11         & 0,874             & 0,876            & 201                     \\ \hline
  features\_20\_40    & 0                   & euclidean         & 12         & 0,875             & 0,878            & 79                      \\ \hline
  features\_20\_40    & 0                   & manhattan         & 12         & 0,875             & 0,878            & 120                     \\ \hline
  features\_20\_40    & 1                   & euclidean         & 12         & 0,875             & 0,878            & 162                     \\ \hline
  features\_20\_40    & 1                   & manhattan         & 12         & 0,875             & 0,878            & 204                     \\ \hline
  features\_46\_36    & 0                   & euclidean         & 13         & 0,877             & 0,880            & 679                     \\ \hline
  features\_46\_36    & 0                   & manhattan         & 13         & 0,877             & 0,880            & 764                     \\ \hline
  features\_46\_36    & 1                   & euclidean         & 13         & 0,877             & 0,880            & 852                     \\ \hline
  features\_46\_36    & 1                   & manhattan         & 13         & 0,877             & 0,880            & 938                     \\ \hline
  features\_10\_20    & 0                   & euclidean         & 13         & 0,877             & 0,880            & 10                      \\ \hline
  features\_10\_20    & 0                   & manhattan         & 13         & 0,877             & 0,880            & 20                      \\ \hline
  features\_10\_20    & 1                   & euclidean         & 13         & 0,877             & 0,880            & 30                      \\ \hline
  features\_10\_20    & 1                   & manhattan         & 13         & 0,877             & 0,880            & 40                      \\ \hline
  \end{tabular}
  \caption{Piores Resultados}
  \label{tab:resultados_piores}
\end{table}

\section{Comparação das Matrizes de Confusão}

Para cada execução, criou-se um arquivo de resultados que também armazena as matrizes de confusão.

A Tabela \ref{tab:matriz_confusao_melhor} demonstra a matriz de confusão para o melhor resultado, enquanto que a Tabela \ref{tab:matriz_confusao_pior} demonstra a matriz de confusão para o pior resultado.

É possível notar que apesar dos erros persistirem na classificação, como por exemplo em: [[0,2],[1,2],[1,3],[1,4],[1,6],[1,7],[1,8],[1,9], eles diminuram consideravelmente. Como por exemplo, no pior caso, a classificação [1,4] foi classificada erroniamente 11 vezes, enquanto que no melhor caso, o erro ocorreu em 8 vezes.

Isso acontece, pois, aumentar o número de \textit{pixels} analisados nas imagens, geram representações mais precisas, porém, como o método é o mesmo, pôde-se observar que os equívocos continuaram existindo nos mesmos lugares, mesmo que em menor número.

\begin{table}[!htb]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
  \hline
  94 & 1  & 0   & 0  & 0  & 1  & 1   & 0  & 0  & 0   \\ \hline
  0  & 93 & 0   & 0  & 0  & 1  & 0   & 0  & 0  & 1   \\ \hline
  1  & 1  & 101 & 1  & 0  & 0  & 0   & 4  & 1  & 2   \\ \hline
  0  & 1  & 0   & 99 & 0  & 1  & 0   & 0  & 2  & 0   \\ \hline
  0  & 8  & 0   & 0  & 84 & 0  & 1   & 0  & 0  & 2   \\ \hline
  2  & 0  & 0   & 5  & 0  & 89 & 1   & 0  & 0  & 0   \\ \hline
  1  & 5  & 0   & 0  & 0  & 0  & 100 & 0  & 0  & 0   \\ \hline
  0  & 3  & 1   & 0  & 1  & 0  & 0   & 88 & 0  & 4   \\ \hline
  0  & 3  & 0   & 1  & 1  & 2  & 0   & 1  & 79 & 0   \\ \hline
  0  & 1  & 0   & 0  & 1  & 0  & 0   & 10 & 0  & 100 \\ \hline
  \end{tabular}
  \caption{Matriz de Confusão - Melhor Caso}
  \label{tab:matriz_confusao_melhor}
\end{table}

\begin{table}[!htb]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
  \hline
  94 & 1  & 0  & 0  & 0  & 2  & 0  & 0  & 0  & 0  \\ \hline
  0  & 94 & 0  & 1  & 0  & 0  & 0  & 0  & 0  & 0  \\ \hline
  2  & 8  & 92 & 1  & 1  & 0  & 3  & 4  & 0  & 0  \\ \hline
  0  & 1  & 1  & 98 & 0  & 0  & 0  & 2  & 1  & 0  \\ \hline
  0  & 11 & 1  & 0  & 79 & 0  & 1  & 1  & 0  & 2  \\ \hline
  2  & 1  & 0  & 7  & 0  & 86 & 1  & 0  & 0  & 0  \\ \hline
  1  & 9  & 0  & 0  & 0  & 0  & 96 & 0  & 0  & 0  \\ \hline
  0  & 11 & 0  & 0  & 1  & 0  & 0  & 81 & 0  & 4  \\ \hline
  0  & 7  & 0  & 6  & 0  & 3  & 0  & 3  & 67 & 1  \\ \hline
  0  & 4  & 0  & 0  & 4  & 0  & 0  & 14 & 0  & 90 \\ \hline
  \end{tabular}
  \caption{Matriz de Confusão - Pior Caso}
  \label{tab:matriz_confusao_pior}
\end{table}

\section{Código Fonte}

Os códigos preparados podem ser analisados através do repositório: https://github.com/diogocezar/machine-learning/tree/master/lab1/src

\end{document}